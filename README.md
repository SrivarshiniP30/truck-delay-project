# truck-delay-project
A project to analyze and predict truck delays.
Truck Delay Classification and ETA Prediction
This project focuses on building a machine learning model to predict truck delays and estimate arrival times (ETA). It involves a comprehensive data science workflow, from data collection and cleaning to feature engineering, model training, and evaluation. The solution leverages various machine learning algorithms and MLOps practices for robust model development and deployment.

ğŸŒŸ Key Features
End-to-End ML Pipeline: Demonstrates a complete machine learning lifecycle, including data ingestion, cleaning, feature engineering, model training, and evaluation.

Data-Driven Insights: Analyzes various factors influencing truck delays, such as weather conditions, traffic patterns, driver behavior, and route characteristics.

Predictive Modeling: Implements and evaluates multiple machine learning algorithms (e.g., Logistic Regression, Random Forest, XGBoost) for delay classification and ETA prediction.

MLOps Integration: Utilizes MLflow for experiment tracking, model versioning, and potential deployment, ensuring reproducibility and efficient model management.

Data Preparation & Cleaning: Includes robust pipelines for handling missing values, outliers, and transforming raw data into a suitable format for modeling.

Exploratory Data Analysis (EDA): In-depth analysis to understand data distributions, correlations, and identify key features impacting truck delays.

ğŸ› ï¸ Technologies Used
Programming Languages: Python

Machine Learning Libraries: Scikit-learn, XGBoost

Data Manipulation: Pandas, NumPy

Notebooks: Jupyter Notebook

MLOps: MLflow

Database (Mock/Example): PostgreSQL (referenced in truck-eta-postgres.sql)

ğŸ“ Project Structure
TruckProject/
â”œâ”€â”€ Truck_Delay_Classification/
â”‚   â”œâ”€â”€ Data/
â”‚   â”‚   â”œâ”€â”€ Backup/
â”‚   â”‚   â””â”€â”€ Training_Data/
â”‚   â”œâ”€â”€ Notebooks/
â”‚   â”œâ”€â”€ Pipelines/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â””â”€â”€ components/
â”‚   â”œâ”€â”€ .gitignore
â”‚   â”œâ”€â”€ 1.Data_Preparation.md
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ setup.py
â”œâ”€â”€ mlruns/                 # MLflow experiment tracking data
â”œâ”€â”€ app.py                   # Main application/inference script
â”œâ”€â”€ best_model.pkl           # Trained machine learning model
â”œâ”€â”€ best_params.json         # Best parameters for models
â”œâ”€â”€ cleanedDf.csv            # Cleaned dataset
â”œâ”€â”€ combineddf.csv           # Combined dataset
â”œâ”€â”€ data.json                # Configuration/data metadata
â”œâ”€â”€ dataCleaning(WRONG).ipynb # Example of iterative development/refinement
â”œâ”€â”€ dataCleaningPreprocessing(STEP 3).ipynb
â”œâ”€â”€ dataCollection(STEP 2).ipynb
â”œâ”€â”€ deployed_Model_Eval2.ipynb
â”œâ”€â”€ eda(FINAL STEP4).ipynb
â”œâ”€â”€ eda(STEP 4).ipynb
â”œâ”€â”€ feature_names.json
â”œâ”€â”€ final_data.csv           # Final processed data (large file, handled by LFS)
â”œâ”€â”€ final_data2.csv
â”œâ”€â”€ loadData1(WRONG).py
â”œâ”€â”€ loadData2(WRONG).py
â”œâ”€â”€ loadData3(STEP 1).py
â”œâ”€â”€ logRegMlFlow.py
â”œâ”€â”€ mlflow1.py
â”œâ”€â”€ mlflow2.py
â”œâ”€â”€ modelDeployed.py
â”œâ”€â”€ modelTrainingLogReg.ipynb
â”œâ”€â”€ modelTrainingLogReg2.ipynb
â”œâ”€â”€ modelTrainingRandomForest.ipynb
â”œâ”€â”€ modelTrainingRandomForest2.ipynb
â”œâ”€â”€ modelTrainingXG.ipynb
â”œâ”€â”€ modelTrainingXG2.ipynb
â”œâ”€â”€ models.ipynb
â”œâ”€â”€ model_Data.csv           # Raw/intermediate data (large file, handled by LFS)
â”œâ”€â”€ X_test.csv
â””â”€â”€ y_test.csv

ğŸš€ Setup and Installation
To set up and run this project locally, follow these steps:

Clone the repository:

git clone https://github.com/SrivarshiniP30/truck-delay-project.git
cd truck-delay-project

Install Git LFS:
Ensure Git Large File Storage (LFS) is installed on your system to handle large data and model files.

git lfs install

Pull LFS files:

git lfs pull

Create a virtual environment (recommended):

python -m venv venv
# On Windows:
.\venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate

Install dependencies:

pip install -r Truck_Delay_Classification/requirements.txt

(Note: If requirements.txt is missing or incomplete, you may need to manually install pandas, numpy, scikit-learn, xgboost, mlflow, jupyter.)

ğŸ“Š Usage
The project workflow is primarily demonstrated through the Jupyter Notebooks located in the Truck_Delay_Classification/Notebooks/ directory.

Data Collection & Ingestion: Refer to dataCollection(STEP 2).ipynb and loadData3(STEP 1).py.

Data Cleaning & Preprocessing: Explore dataCleaningPreprocessing(STEP 3).ipynb.

EDA & Feature Engineering: See EDA&FeatureEng(STEP 4).ipynb and eda(FINAL STEP4).ipynb.

Model Training & Evaluation: Check modelTrainingRandomForest.ipynb, modelTrainingXG.ipynb, modelTrainingLogReg.ipynb for different model approaches.

MLflow Tracking: mlflow1.py and mlflow2.py demonstrate MLflow integration.

Model Deployment/Inference: modelDeployed.py and app.py are likely used for serving the model.

To run the Jupyter Notebooks:

jupyter notebook

This will open a browser window where you can navigate through the notebooks and execute the code cells.

ğŸ“ Contact
For any questions or further information, please feel free to reach out.
